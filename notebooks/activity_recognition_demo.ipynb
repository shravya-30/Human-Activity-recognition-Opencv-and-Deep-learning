{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition Demo\n",
    "\n",
    "This notebook demonstrates the complete workflow for recognizing human activities from video data using deep learning and OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.video_processor import VideoProcessor\n",
    "from src.activity_classifier import ActivityRecognizer\n",
    "from src.utils import visualize_predictions, get_video_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video processor\n",
    "processor = VideoProcessor(target_frame_size=(224, 224))\n",
    "\n",
    "# Initialize activity recognizer\n",
    "recognizer = ActivityRecognizer(\n",
    "    model_path='../models/pretrained_model.h5'\n",
    ")\n",
    "\n",
    "print(\"✓ Components initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify video path\n",
    "video_path = '../data/sample_videos/example.mp4'\n",
    "\n",
    "# Get video information\n",
    "video_info = get_video_info(video_path)\n",
    "print(\"Video Information:\")\n",
    "print(f\"  Duration: {video_info['duration_seconds']:.2f} seconds\")\n",
    "print(f\"  Resolution: {video_info['width']}x{video_info['height']}\")\n",
    "print(f\"  Frame Rate: {video_info['fps']} fps\")\n",
    "print(f\"  Total Frames: {video_info['frame_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the video\n",
    "frames = processor.preprocess_video(\n",
    "    video_path, \n",
    "    num_frames=16,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Frames extracted and preprocessed\")\n",
    "print(f\"  Shape: {frames.shape}\")\n",
    "print(f\"  Data type: {frames.dtype}\")\n",
    "print(f\"  Value range: [{frames.min():.3f}, {frames.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Predict Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top-5 predictions\n",
    "predictions = recognizer.predict(frames, return_top_k=5)\n",
    "\n",
    "# Extract activity names and confidences\n",
    "activities = [pred[0] for pred in predictions]\n",
    "confidences = [pred[1] for pred in predictions]\n",
    "\n",
    "print(\"\\nPredicted Activities:\")\n",
    "print(visualize_predictions(activities, confidences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed predictions\n",
    "print(\"\\nDetailed Prediction Results:\")\n",
    "print(\"─\" * 50)\n",
    "\n",
    "for rank, (activity, confidence) in enumerate(predictions, 1):\n",
    "    print(f\"Rank {rank}: {activity:25s} - {confidence:.2%}\")\n",
    "\n",
    "print(\"─\" * 50)\n",
    "print(f\"\\nTop Prediction: {predictions[0][0]} ({predictions[0][1]:.2%} confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Batch Processing (Multiple Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process multiple videos\n",
    "video_paths = [\n",
    "    '../data/sample_videos/video1.mp4',\n",
    "    '../data/sample_videos/video2.mp4',\n",
    "    '../data/sample_videos/video3.mp4'\n",
    "]\n",
    "\n",
    "# Note: Adjust paths based on your actual video files\n",
    "# results = []\n",
    "# for video_path in video_paths:\n",
    "#     try:\n",
    "#         pred = recognizer.predict_from_video_path(video_path, return_top_k=1)\n",
    "#         results.append((video_path, pred[0]))\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {video_path}: {e}\")\n",
    "\n",
    "print(\"Batch processing example (commented out - enable with actual video files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Video Preprocessing**: Frames are extracted, resized, and normalized for consistent model input\n",
    "2. **Deep Learning Inference**: Pre-trained CNN processes spatial and temporal patterns\n",
    "3. **Activity Classification**: Model outputs probability distribution over 400+ activity classes\n",
    "4. **Confidence Scores**: High confidence indicates the model is certain about the prediction\n",
    "\n",
    "### Project Highlights\n",
    "- Handles real-world video data with varying resolution and frame rates\n",
    "- Uses Kinetic-400 dataset with 400+ human activity classes\n",
    "- Efficient preprocessing pipeline with OpenCV\n",
    "- Supports batch processing for multiple videos\n",
    "- Easily extensible for custom activities or fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
